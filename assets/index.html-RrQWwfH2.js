import{_ as r}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,b as s,a as t,d as a,e as o,r as h,o as l}from"./app-Bn4Nr-M4.js";const d={},Q={class:"MathJax",jax:"SVG",display:"true",style:{position:"relative"}},p={style:{"vertical-align":"-2.308ex"},xmlns:"http://www.w3.org/2000/svg",width:"41.428ex",height:"5.741ex",role:"img",focusable:"false",viewBox:"0 -1517.7 18311.4 2537.7","aria-hidden":"true"};function T(g,i){const e=h("Mermaid");return l(),n("div",null,[i[5]||(i[5]=s('<h2 id="ai发展简史与技术原理" tabindex="-1"><a class="header-anchor" href="#ai发展简史与技术原理"><span><strong>AI发展简史与技术原理</strong></span></a></h2><p>人工智能（AI）作为一门交叉学科，经历了多个发展阶段：</p><ul><li><p><strong>1950s-1980s：符号主义AI</strong>：使用规则和知识图谱来模拟推理，代表系统如Expert System。</p></li><li><p><strong>1980s-2010s：统计学习与神经网络</strong>：神经网络、多层感知器、支持向量机等方法成为主流，尤其是在图像识别、语音识别等领域取得突破。</p></li><li><p><strong>2017至今：大模型时代（LLM）</strong>：Transformer架构的提出（Google的&quot;Attention is All You Need&quot;论文），开启了预训练+微调范式，ChatGPT、Claude、Gemini 等多模态大模型横空出世</p></li></ul><div class="hint-container info"><p class="hint-container-title">AI发展里程碑</p><ul><li><strong>1950s</strong>：图灵测试提出，AI概念诞生</li><li><strong>1980s</strong>：专家系统兴起（如MYCIN医疗诊断）</li><li><strong>1997年</strong>：IBM深蓝击败国际象棋冠军</li><li><strong>2012年</strong>：AlexNet引爆深度学习革命</li><li><strong>2017年</strong>：Transformer架构诞生（GPT、BERT的基础）</li><li><strong>2023年</strong>：ChatGPT推动大模型普及</li></ul></div><h3 id="现代ai核心技术" tabindex="-1"><a class="header-anchor" href="#现代ai核心技术"><span><strong>现代AI核心技术</strong></span></a></h3><ul><li><strong>深度学习</strong>：基于神经网络的表征学习</li><li><strong>Transformer</strong>：自注意力机制解决长序列依赖</li><li><strong>扩散模型</strong>：Stable Diffusion等图像生成基础</li><li><strong>强化学习</strong>：AlphaGo、自动驾驶决策核心</li></ul><div class="hint-container important"><p class="hint-container-title">核心原理：Transformer架构</p><ul><li><strong>Encoder-Decoder结构</strong>：主要用于翻译任务。</li><li><strong>Self-Attention机制</strong>：使得模型能同时关注输入的不同部分，提高理解能力。</li><li><strong>预训练+微调</strong>：大模型先在海量数据上无监督预训练，然后针对特定任务进行微调，提升效果</li></ul></div><h4 id="关键公式示例-注意力机制" tabindex="-1"><a class="header-anchor" href="#关键公式示例-注意力机制"><span><strong>关键公式示例（注意力机制）</strong></span></a></h4>',8)),t("mjx-container",Q,[(l(),n("svg",p,i[0]||(i[0]=[s('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="41" d="M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(750,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1139,0)"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1528,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1972,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(2528,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(2917,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(3195,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(3695,0)"></path></g><g data-mml-node="mo" transform="translate(4251,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(4640,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mo" transform="translate(5431,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(5875.7,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mo" transform="translate(6764.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(7209.3,0)"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g><g data-mml-node="mo" transform="translate(7978.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(8645.1,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mtext" transform="translate(9700.9,0)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(394,0)"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(894,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1200,0)"></path><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1589,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2422,0)"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(2922,0)"></path></g><g data-mml-node="mrow" transform="translate(13317.6,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z"></path></g><g data-mml-node="mfrac" transform="translate(736,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="msup" transform="translate(791,0)"><g data-mml-node="mi"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(974,363) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g><g data-mml-node="msqrt" transform="translate(464.2,-855.6)"><g transform="translate(853,0)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(553,-150) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g><g data-mml-node="mo" transform="translate(0,35.6)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path></g><rect width="971.4" height="60" x="853" y="775.6"></rect></g><rect width="2512.8" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(3488.8,0) translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z"></path></g></g><g data-mml-node="mi" transform="translate(17542.4,0)"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g></g></g>',1)]))),i[1]||(i[1]=t("mjx-assistive-mml",{unselectable:"on",display:"block"},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[t("mtext",null,"Attention"),t("mo",{stretchy:"false"},"("),t("mi",null,"Q"),t("mo",null,","),t("mi",null,"K"),t("mo",null,","),t("mi",null,"V"),t("mo",{stretchy:"false"},")"),t("mo",null,"="),t("mtext",null,"softmax"),t("mrow",{"data-mjx-texclass":"INNER"},[t("mo",{"data-mjx-texclass":"OPEN"},"("),t("mfrac",null,[t("mrow",null,[t("mi",null,"Q"),t("msup",null,[t("mi",null,"K"),t("mi",null,"T")])]),t("msqrt",null,[t("msub",null,[t("mi",null,"d"),t("mi",null,"k")])])]),t("mo",{"data-mjx-texclass":"CLOSE"},")")]),t("mi",null,"V")])],-1))]),i[6]||(i[6]=s(`<hr><h3 id="主流大模型对比" tabindex="-1"><a class="header-anchor" href="#主流大模型对比"><span>主流大模型对比</span></a></h3><table><thead><tr><th><strong>模型</strong></th><th><strong>公司</strong></th><th><strong>特点</strong></th><th><strong>适用场景</strong></th></tr></thead><tbody><tr><td>GPT-4</td><td>OpenAI</td><td>多模态、强推理能力</td><td>通用问答、代码生成</td></tr><tr><td>Claude 3</td><td>Anthropic</td><td>长上下文（200K tokens）</td><td>文档分析、法律文本</td></tr><tr><td>Gemini 1.5</td><td>Google</td><td>多模态交互最优</td><td>跨模态搜索、视频理解</td></tr><tr><td>LLaMA 3</td><td>Meta</td><td>开源可商用（8B-70B参数）</td><td>企业私有化部署</td></tr><tr><td>Mistral 7B</td><td>Mistral AI</td><td>轻量级高效</td><td>边缘设备、快速推理</td></tr></tbody></table><div class="hint-container tip"><p class="hint-container-title">模型架构对比</p><ul><li><strong>自回归模型</strong>（GPT系列）：逐token生成，适合文本创作</li><li><strong>双向编码模型</strong>（BERT）：上下文理解，适合分类任务</li><li><strong>混合架构</strong>（T5）：编码器-解码器，适合翻译/摘要</li></ul></div><hr><h3 id="开发者工具推荐" tabindex="-1"><a class="header-anchor" href="#开发者工具推荐"><span><strong>开发者工具推荐</strong></span></a></h3><table><thead><tr><th><strong>工具</strong></th><th><strong>用途</strong></th><th><strong>链接</strong></th></tr></thead><tbody><tr><td>Hugging Face</td><td>模型库与数据集</td><td><a href="https://huggingface.co" target="_blank" rel="noopener noreferrer">huggingface.co</a></td></tr><tr><td>Ollama</td><td>本地运行大模型</td><td><a href="https://ollama.ai" target="_blank" rel="noopener noreferrer">ollama.ai</a></td></tr><tr><td>LangChain</td><td>AI应用开发框架</td><td><a href="https://langchain.com" target="_blank" rel="noopener noreferrer">langchain.com</a></td></tr><tr><td>LM Studio</td><td>本地GUI模型管理</td><td><a href="https://lmstudio.ai" target="_blank" rel="noopener noreferrer">lmstudio.ai</a></td></tr></tbody></table><hr><h3 id="token" tabindex="-1"><a class="header-anchor" href="#token"><span><strong>Token</strong></span></a></h3><p>Token是AI大模型处理文本的基本单位，它代表了模型输入输出的最小语义片段。</p><p>在自然语言处理(NLP)中，Token可以是一个单词、子词(subword)或符号</p><ul><li>OpenAI Token计算器：<a href="https://platform.openai.com/tokenizer" target="_blank" rel="noopener noreferrer">https://platform.openai.com/tokenizer</a></li><li>第三方Token计算：<a href="https://tiktoken.aigc2d.com/" target="_blank" rel="noopener noreferrer">https://tiktoken.aigc2d.com/</a></li></ul><div class="hint-container info"><p class="hint-container-title">Token的成本计算方式</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>总成本 = (输入Token数 + 输出Token数) × 每Token单价</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>影响成本的因素</p><ul><li><strong>模型类型</strong>：不同模型(如GPT-3.5与GPT-4)的Token单价不同</li><li><strong>API提供商</strong>：各平台定价策略有差异</li><li><strong>上下文长度</strong>：长上下文需要更多计算资源</li><li><strong>请求频率</strong>：批量处理可能享受折扣</li></ul></div><p>典型定价示例(以OpenAI为例，2023年数据)</p><table><thead><tr><th>模型</th><th>输入单价(每1K Tokens)</th><th>输出单价(每1K Tokens)</th></tr></thead><tbody><tr><td>GPT-3.5 Turbo</td><td>$0.0015</td><td>$0.002</td></tr><tr><td>GPT-4</td><td>$0.03</td><td>$0.06</td></tr><tr><td>GPT-4-32k</td><td>$0.06</td><td>$0.12</td></tr></tbody></table><p>实际成本计算案例-假设使用GPT-4模型：</p><ul><li>输入：1,500 Tokens</li><li>输出：800 Tokens</li><li>计算：<div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>输入成本 = ceil(1500/1000) × $0.03 = 2 × $0.03 = $0.06</span></span>
<span class="line"><span>输出成本 = ceil(800/1000) × $0.06 = 1 × $0.06 = $0.06</span></span>
<span class="line"><span>总成本 = $0.06 + $0.06 = $0.12</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><div class="hint-container tip"><p class="hint-container-title">Token成本优化技巧</p><h4 id="_1-输入优化策略" tabindex="-1"><a class="header-anchor" href="#_1-输入优化策略"><span>1. 输入优化策略</span></a></h4><p><strong>精简提示词(Prompt Pruning)</strong></p><ul><li>删除不必要的礼貌用语和冗余信息</li><li>示例优化：<div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>差: &quot;你好，请问你能帮我总结一下这篇文章吗？非常感谢你的帮助！&quot;</span></span>
<span class="line"><span>优: &quot;总结这篇文章：&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><p><strong>上下文压缩技术</strong></p><ul><li>使用向量检索只提取相关上下文</li><li>实现摘要式上下文而非完整文本</li><li>采用递归检索策略</li></ul><p><strong>结构化输入</strong></p><ul><li>使用JSON等结构化格式提高信息密度</li><li>示例：<div class="language-json line-numbers-mode" data-highlighter="shiki" data-ext="json" data-title="json" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">{</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">&quot;task&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;summary&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">&quot;text&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;...&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li></ul><h4 id="_2-输出优化策略" tabindex="-1"><a class="header-anchor" href="#_2-输出优化策略"><span>2. 输出优化策略</span></a></h4><p><strong>限制输出长度</strong></p><ul><li>设置max_tokens参数</li><li>明确要求简洁回答<div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>&quot;用不超过50字回答：...&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li></ul><p><strong>输出格式控制</strong></p><ul><li>要求特定格式(如列表、表格)提高信息密度</li><li>示例：<div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>&quot;以表格形式列出优缺点，每点不超过5个词&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li></ul><p><strong>流式处理</strong></p><ul><li>对长内容分块处理，及时中断不需要的部分</li></ul><h4 id="_3-系统级优化" tabindex="-1"><a class="header-anchor" href="#_3-系统级优化"><span>3. 系统级优化</span></a></h4><p><strong>缓存机制</strong></p><ul><li>缓存常见问题的标准回答</li><li>实现Token-aware缓存策略</li></ul><p><strong>模型选择策略</strong></p><ul><li>简单任务使用低成本模型</li><li>复杂任务才用高端模型</li></ul><p><strong>批量处理</strong></p><ul><li>合并多个请求为批量调用</li><li>实现请求队列和聚合</li></ul><h3 id="_4-监控与分析" tabindex="-1"><a class="header-anchor" href="#_4-监控与分析"><span>4. 监控与分析</span></a></h3><p><strong>Token使用监控</strong></p><ul><li>实现实时Token计数器</li><li>设置预算警报阈值</li></ul><p><strong>成本分析仪表盘</strong></p><ul><li>按功能/部门/用户分析Token消耗</li><li>识别高成本热点</li></ul><p><strong>A/B测试</strong></p><ul><li>比较不同提示词的Token效率</li><li>优化高频率查询</li></ul></div><hr><h3 id="prompt-engineering" tabindex="-1"><a class="header-anchor" href="#prompt-engineering"><span><strong>Prompt Engineering</strong></span></a></h3><p>提示词工程（Prompt Engineering），简单来说，就是输入给 AI 的指令</p><div class="hint-container info"><p class="hint-container-title">大模型提示词分类与设计指南</p><h4 id="基于角色的分类-核心分类" tabindex="-1"><a class="header-anchor" href="#基于角色的分类-核心分类"><span>基于角色的分类（核心分类）</span></a></h4><ol><li>用户提示词(User Prompt)</li></ol><ul><li><strong>定义</strong>：用户直接输入的请求或指令</li><li><strong>功能</strong>：明确告诉AI&quot;做什么&quot;</li></ul><p>示例：&quot;总结这篇文章的核心观点&quot;</p><ol start="2"><li>系统提示词(System Prompt)</li></ol><ul><li><strong>定义</strong>：设定AI行为规则的隐藏指令</li><li><strong>功能</strong>：定义AI的角色定位和能力边界</li><li><strong>关键要素</strong>： <ul><li>角色身份（如&quot;资深营养师&quot;）</li><li>专业领域（如&quot;擅长制定减肥食谱&quot;）</li><li>回答风格（如&quot;使用通俗易懂的语言&quot;）</li><li>限制条件（如&quot;不提供医疗诊断&quot;）</li></ul></li></ul><ol start="3"><li>助手提示词(Assistant Prompt)</li></ol><ul><li><strong>定义</strong>：AI的响应内容</li><li><strong>功能</strong>：在多轮对话中形成上下文记忆</li><li><strong>应用</strong>：可预设引导性回复塑造对话方向</li></ul><h4 id="基于功能的分类" tabindex="-1"><a class="header-anchor" href="#基于功能的分类"><span>基于功能的分类</span></a></h4><ol><li><strong>指令型</strong>：明确任务（&quot;将以下文本翻译成法语&quot;）</li><li><strong>对话型</strong>：自然交流（&quot;你对区块链技术怎么看？&quot;）</li><li><strong>创意型</strong>：内容生成（&quot;创作一首关于秋天的俳句&quot;）</li><li><strong>角色扮演型</strong>：特定身份（&quot;作为莎士比亚评论这首诗&quot;）</li><li><strong>少样本学习型</strong>：示例引导（提供2-3个示例规范输出格式）</li></ol><h4 id="基于复杂度的分类" tabindex="-1"><a class="header-anchor" href="#基于复杂度的分类"><span>基于复杂度的分类</span></a></h4><ol><li><strong>简单型</strong>：单一指令（&quot;解释量子计算&quot;）</li><li><strong>复合型</strong>：多重要求（&quot;分析代码+找错+改进建议&quot;）</li><li><strong>链式型</strong>：分步执行（首先生成大纲→再扩展内容）</li><li><strong>模板型</strong>：结构化变量（&quot;作为{领域}专家回答{问题}&quot;）</li></ol></div><ol><li><strong>角色定义</strong>：系统提示词决定AI的专业性和边界</li><li><strong>明确度</strong>：用户提示词越具体，输出质量越高</li><li><strong>上下文管理</strong>：合理利用助手提示词引导对话</li><li><strong>复杂度匹配</strong>：根据需求选择适当提示词结构</li></ol><hr><h3 id="微调-fine-tuning" tabindex="-1"><a class="header-anchor" href="#微调-fine-tuning"><span><strong>微调(Fine-tuning)</strong></span></a></h3><p>微调技术分类：</p><ul><li><strong>全参数微调（Full Finetuning）</strong>：调优全部模型参数，成本高但适应性强。</li><li><strong>参数高效微调（PEFT）</strong>：如LoRA、QLoRA，只调整少量参数，部署灵活。</li><li><strong>指令微调（SFT）</strong>：结合人类标注数据，让模型更符合期望指令。</li><li><strong>RLHF（基于人类反馈的强化学习）</strong>：OpenAI使用于ChatGPT的重要优化方法。</li></ul><hr><p><strong>全参数微调</strong>：更新所有权重，需大量计算资源</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">model.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">train</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> batch </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> dataloader:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    outputs </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> model</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(**batch)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    loss </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> outputs.loss</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    loss.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">backward</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    optimizer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">step</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>高效微调方法</strong>：</p><ul><li><strong>LoRA</strong>：低秩适配（仅训练新增的小矩阵）</li><li><strong>Adapter</strong>：插入小型网络模块</li><li><strong>QLoRA</strong>：4bit量化+LoRA，显存需求降低70%</li></ul><hr><h2 id="核心扩展技术解析" tabindex="-1"><a class="header-anchor" href="#核心扩展技术解析"><span><strong>核心扩展技术解析</strong></span></a></h2><h3 id="function-calling" tabindex="-1"><a class="header-anchor" href="#function-calling"><span><strong>Function Calling</strong></span></a></h3><ul><li><strong>作用</strong>：让大模型触发外部工具（如API、数据库）</li><li><strong>示例流程</strong>：<div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">tools </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [{</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &quot;type&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;function&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &quot;function&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: {</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;name&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;get_weather&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;parameters&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: {</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;location&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;string&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    }</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">response </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> client.chat.completions.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">create</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">    model</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;gpt-4&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">    messages</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[{</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;role&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;user&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;content&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;北京天气如何？&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}],</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">    tools</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">tools</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><hr><h3 id="mcp-模型上下文协议" tabindex="-1"><a class="header-anchor" href="#mcp-模型上下文协议"><span><strong>MCP(模型上下文协议)</strong></span></a></h3><p><strong>MCP（模型上下文协议）</strong></p><ul><li><strong>架构设计</strong>：标准化接口实现AI与外部系统交互</li><li><strong>典型应用</strong>： <ul><li>百度地图POI数据调用：整合实时人流热力图生成旅游路线</li><li>实现步骤：</li></ul></li></ul><ol><li>部署MCP Agent策略</li><li>配置API端点与查询条件</li></ol><hr><h3 id="rag-检索增强生成" tabindex="-1"><a class="header-anchor" href="#rag-检索增强生成"><span><strong>RAG(检索增强生成)</strong></span></a></h3>`,43)),t("ul",null,[t("li",null,[i[2]||(i[2]=t("strong",null,"架构",-1)),i[3]||(i[3]=a("：")),o(e,{id:"mermaid-912",code:"eJxLL0osyFDwCeJSUHCMfj5lxbOO7S+nr3u5aEasgq6unYJT9NMJE1+29z+buuFZ77qnuyY/W9zwfMuiWKByJ7AC5+jns3c8bd38bFr7s4WLn3e2P1u3FSTrDJZ1iX66ZPmzFQufzut+PmX+s44Jz9dOebawI5YLAN/cPZI="})]),i[4]||(i[4]=t("li",null,[t("strong",null,"实现工具"),a("： "),t("ul",null,[t("li",null,[t("strong",null,"LlamaIndex"),a("：文档索引与检索")]),t("li",null,[t("strong",null,"FAISS"),a("：高效向量搜索库")])])],-1))]),i[7]||(i[7]=s('<hr><h2 id="大模型接入方式" tabindex="-1"><a class="header-anchor" href="#大模型接入方式"><span>大模型接入方式</span></a></h2><ul><li><p>云服务</p></li><li><p>本地部署（私有部署）</p></li></ul><h3 id="ai应用平台" tabindex="-1"><a class="header-anchor" href="#ai应用平台"><span>AI应用平台</span></a></h3><ul><li><a href="https://bailian.console.aliyun.com/console?tab=model#/model-market" target="_blank" rel="noopener noreferrer">阿里云百炼</a></li></ul><h3 id="ai软件客户端" tabindex="-1"><a class="header-anchor" href="#ai软件客户端"><span>AI软件客户端</span></a></h3><p>cherry studio</p><p>cursor/trae...</p><h3 id="程序调用" tabindex="-1"><a class="header-anchor" href="#程序调用"><span>程序调用</span></a></h3><p>模型服务灵积（Dashscope）：<a href="https://www.aliyun.com/product/dashscope" target="_blank" rel="noopener noreferrer">https://www.aliyun.com/product/dashscope</a></p><hr><h2 id="ai应用场景及未来趋势" tabindex="-1"><a class="header-anchor" href="#ai应用场景及未来趋势"><span><strong>AI应用场景及未来趋势</strong></span></a></h2><p><strong>1. 代码辅助</strong></p><ul><li><strong>GitHub Copilot</strong>：实时代码补全</li><li><strong>CodeLlama</strong>：开源代码生成模型</li></ul><p><strong>2. 智能问答系统</strong></p><ul><li><strong>RAG+GPT</strong>：企业知识库问答</li><li><strong>LangChain</strong>：构建AI Agent流水线</li></ul><p><strong>3. 计算机视觉</strong></p><ul><li><strong>YOLOv9</strong>：实时目标检测</li><li><strong>SAM</strong>：Meta图像分割一切模型</li></ul><p><strong>4. 语音交互</strong></p><ul><li><strong>Whisper</strong>：语音转录（支持100+语言）</li><li><strong>VALL-E</strong>：微软高保真语音克隆</li></ul><hr><div class="hint-container info"><p class="hint-container-title">未来趋势与挑战</p><ul><li><strong>多模态统一模型</strong>：图像、语音、视频、文本全面融合。</li><li><strong>Agent化发展</strong>：AI不只是工具，而是自治行动体。</li><li><strong>个性化模型微调工具普及</strong>：人人可微调小型个人助手。</li><li><strong>AI+IoT、边缘AI部署加速</strong>：设备端推理、低功耗大模型落地。</li></ul><hr><ul><li><strong>小型化</strong>：1B参数模型达到70B模型能力（如Phi-3）</li><li><strong>多模态</strong>：文本/图像/视频/3D统一处理</li><li><strong>安全风险</strong>：幻觉（Hallucination）缓解与对齐（Alignment）</li></ul></div><p><strong>行动建议</strong>：</p><ol><li>掌握RAG+Function Calling构建企业级应用</li><li>关注开源模型（如Llama 3）的垂直领域微调</li></ol>',24))])}const u=r(d,[["render",T],["__file","index.html.vue"]]),m=JSON.parse('{"path":"/AI/","title":"Artificial Intelligence","lang":"en-US","frontmatter":{"dir":{"order":1,"text":"Artificial Intelligence"},"index":false,"title":"Artificial Intelligence","description":"AI发展简史与技术原理 人工智能（AI）作为一门交叉学科，经历了多个发展阶段： 1950s-1980s：符号主义AI：使用规则和知识图谱来模拟推理，代表系统如Expert System。 1980s-2010s：统计学习与神经网络：神经网络、多层感知器、支持向量机等方法成为主流，尤其是在图像识别、语音识别等领域取得突破。 2017至今：大模型时代（LL...","head":[["meta",{"property":"og:url","content":"https://x.app/AI/"}],["meta",{"property":"og:site_name","content":"doc"}],["meta",{"property":"og:title","content":"Artificial Intelligence"}],["meta",{"property":"og:description","content":"AI发展简史与技术原理 人工智能（AI）作为一门交叉学科，经历了多个发展阶段： 1950s-1980s：符号主义AI：使用规则和知识图谱来模拟推理，代表系统如Expert System。 1980s-2010s：统计学习与神经网络：神经网络、多层感知器、支持向量机等方法成为主流，尤其是在图像识别、语音识别等领域取得突破。 2017至今：大模型时代（LL..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-05-09T15:14:45.000Z"}],["meta",{"property":"article:author","content":"ventixy"}],["meta",{"property":"article:modified_time","content":"2025-05-09T15:14:45.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Artificial Intelligence\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-05-09T15:14:45.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"ventixy\\",\\"url\\":\\"https://www.ventix.top\\"}]}"]]},"headers":[{"level":2,"title":"AI发展简史与技术原理","slug":"ai发展简史与技术原理","link":"#ai发展简史与技术原理","children":[{"level":3,"title":"现代AI核心技术","slug":"现代ai核心技术","link":"#现代ai核心技术","children":[]},{"level":3,"title":"主流大模型对比","slug":"主流大模型对比","link":"#主流大模型对比","children":[]},{"level":3,"title":"开发者工具推荐","slug":"开发者工具推荐","link":"#开发者工具推荐","children":[]},{"level":3,"title":"Token","slug":"token","link":"#token","children":[]},{"level":3,"title":"Prompt Engineering","slug":"prompt-engineering","link":"#prompt-engineering","children":[]},{"level":3,"title":"微调(Fine-tuning)","slug":"微调-fine-tuning","link":"#微调-fine-tuning","children":[]}]},{"level":2,"title":"核心扩展技术解析","slug":"核心扩展技术解析","link":"#核心扩展技术解析","children":[{"level":3,"title":"Function Calling","slug":"function-calling","link":"#function-calling","children":[]},{"level":3,"title":"MCP(模型上下文协议)","slug":"mcp-模型上下文协议","link":"#mcp-模型上下文协议","children":[]},{"level":3,"title":"RAG(检索增强生成)","slug":"rag-检索增强生成","link":"#rag-检索增强生成","children":[]}]},{"level":2,"title":"大模型接入方式","slug":"大模型接入方式","link":"#大模型接入方式","children":[{"level":3,"title":"AI应用平台","slug":"ai应用平台","link":"#ai应用平台","children":[]},{"level":3,"title":"AI软件客户端","slug":"ai软件客户端","link":"#ai软件客户端","children":[]},{"level":3,"title":"程序调用","slug":"程序调用","link":"#程序调用","children":[]}]},{"level":2,"title":"AI应用场景及未来趋势","slug":"ai应用场景及未来趋势","link":"#ai应用场景及未来趋势","children":[]}],"git":{"createdTime":1745203800000,"updatedTime":1746803685000,"contributors":[{"name":"drizzle","email":"msdrizzle@outlook.com","commits":3}]},"readingTime":{"minutes":8.39,"words":2516},"filePathRelative":"AI/README.md","localizedDate":"April 21, 2025","excerpt":"<h2><strong>AI发展简史与技术原理</strong></h2>\\n<p>人工智能（AI）作为一门交叉学科，经历了多个发展阶段：</p>\\n<ul>\\n<li>\\n<p><strong>1950s-1980s：符号主义AI</strong>：使用规则和知识图谱来模拟推理，代表系统如Expert System。</p>\\n</li>\\n<li>\\n<p><strong>1980s-2010s：统计学习与神经网络</strong>：神经网络、多层感知器、支持向量机等方法成为主流，尤其是在图像识别、语音识别等领域取得突破。</p>\\n</li>\\n<li>\\n<p><strong>2017至今：大模型时代（LLM）</strong>：Transformer架构的提出（Google的\\"Attention is All You Need\\"论文），开启了预训练+微调范式，ChatGPT、Claude、Gemini 等多模态大模型横空出世</p>\\n</li>\\n</ul>","autoDesc":true}');export{u as comp,m as data};
