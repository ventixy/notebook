import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,b as t,o as l}from"./app-FLXCRxYa.js";const e={};function n(h,i){return l(),a("div",null,i[0]||(i[0]=[t(`<h2 id="yolo快速入门" tabindex="-1"><a class="header-anchor" href="#yolo快速入门"><span>yolo快速入门</span></a></h2><p>yolov8仓库地址：<a href="https://github.com/ultralytics/ultralytics" target="_blank" rel="noopener noreferrer">https://github.com/ultralytics/ultralytics</a></p><p>yolov8官方文档：<a href="https://docs.ultralytics.com" target="_blank" rel="noopener noreferrer">https://docs.ultralytics.com</a></p><h3 id="yolov8的安装" tabindex="-1"><a class="header-anchor" href="#yolov8的安装"><span>yolov8的安装</span></a></h3><p>使用yolov8需要 python&gt;=3.8 和 PyTorch&gt;=1.8 的环境，参照：<a href="/python/BasicSyntax/env">Python常用环境的安装</a></p><p>Pip install the ultralytics package including all requirements in a Python&gt;=3.8 environment with PyTorch&gt;=1.8.</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">conda</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> create</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --name</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> yolov8</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --clone</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pytorch</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">conda</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> activate</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> yolov8</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ultralytics</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>YOLOv8 may be used directly in the Command Line Interface (CLI) with a yolo command:</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">yolo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> predict</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> model=yolov8n.pt</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> source=&#39;https://ultralytics.com/images/bus.jpg&#39;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>CLI文档：<a href="https://docs.ultralytics.com/usage/cli" target="_blank" rel="noopener noreferrer">https://docs.ultralytics.com/usage/cli</a></p><h3 id="预训练权重" tabindex="-1"><a class="header-anchor" href="#预训练权重"><span>预训练权重</span></a></h3><h3 id="python代码示例" tabindex="-1"><a class="header-anchor" href="#python代码示例"><span>python代码示例</span></a></h3><p>YOLOv8 may also be used directly in a Python environment, and accepts the same arguments as in the CLI example above:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ultralytics </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;"> YOLO</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Load a model</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">model </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> YOLO</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;yolov8n.yaml&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># build a new model from scratch</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">model </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> YOLO</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;yolov8n.pt&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># load a pretrained model (recommended for training)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Use the model</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">model.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">train</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">data</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;coco128.yaml&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">epochs</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># train the model</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">metrics </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> model.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">val</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># evaluate model performance on the validation set</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">results </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> model</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;https://ultralytics.com/images/bus.jpg&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># predict on an image</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">path </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> model.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">export</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">format</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;onnx&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># export the model to ONNX format</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>See YOLOv8 <a href="https://docs.ultralytics.com/usage/python" target="_blank" rel="noopener noreferrer">Python Docs</a> for more examples.</p><h2 id="数据集准备" tabindex="-1"><a class="header-anchor" href="#数据集准备"><span>数据集准备</span></a></h2><p>yolov8 官网给出的数据准备流程 --&gt; <a href="https://docs.ultralytics.com/datasets/#steps-to-contribute-a-new-dataset" target="_blank" rel="noopener noreferrer">Steps to Contribute a New Dataset</a>:</p><ol><li><p><strong>Collect Images</strong>: Gather the images that belong to the dataset. These could be collected from various sources, such as public databases or your own collection.</p></li><li><p><strong>Annotate Images</strong>: Annotate these images with bounding boxes, segments, or keypoints, depending on the task.</p></li><li><p><strong>Export Annotations</strong>: Convert these annotations into the YOLO *.txt file format which Ultralytics supports.</p></li><li><p><strong>Organize Dataset</strong>: Arrange your dataset into the correct folder structure. You should have <code>train/</code> and <code>val/</code> top-level directories, and within each, an <code>images/</code> and <code>labels/</code> subdirectory.</p></li></ol><div class="language-txt line-numbers-mode" data-highlighter="shiki" data-ext="txt" data-title="txt" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>dataset/</span></span>
<span class="line"><span>├── train/</span></span>
<span class="line"><span>│   ├── images/</span></span>
<span class="line"><span>│   └── labels/</span></span>
<span class="line"><span>└── val/</span></span>
<span class="line"><span>    ├── images/</span></span>
<span class="line"><span>    └── labels/</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="5"><li><p><strong>Create a <code>data.yaml</code> File</strong>: In your dataset&#39;s root directory, create a data.yaml file that describes the dataset, classes, and other necessary information.</p></li><li><p><strong>Optimize Images</strong> (Optional): If you want to reduce the size of the dataset for more efficient processing, you can optimize the images using the code below. This is not required, but recommended for smaller dataset sizes and faster download speeds.</p></li></ol><h3 id="标注数据集" tabindex="-1"><a class="header-anchor" href="#标注数据集"><span>标注数据集</span></a></h3><p>常用标注工具：</p><ul><li><p>labelimg 是一种矩形标注工具，常用于目标识别和目标检测，其标记数据输出为.xml和.txt</p></li><li><p>labelme 是一种多边形标注工具，可以准确的将轮廓标注出来，常用于分割，其标记输出格式为json</p></li><li><p>VGG Image Annotator (VIA)</p></li><li><p>CVAT (Computer Vision Annotation Tool)</p></li></ul><p>注意：labelme 生成的标签是 json 文件的格式，后续需要转化成 txt 文件才能被 yolov 使用</p><h3 id="划分数据集" tabindex="-1"><a class="header-anchor" href="#划分数据集"><span>划分数据集</span></a></h3><p>在目标检测的训练过程中，训练集、验证集和测试集扮演着不同的角色：</p><ul><li><p>训练集（Training Set）<br> 训练集是用于模型训练的数据集。目标检测模型通过对训练集中的图像进行学习和参数优化，来掌握目标的特征和上下文信息。训练集通常包含大量的标注数据，<br> 其中目标物体被标记为其位置和类别。模型通过观察训练集中的样本来学习目标的外观和形状，以便能够在后续的预测中对新的图像进行目标检测。</p></li><li><p>验证集（Validation Set）<br> 验证集用于在训练过程中评估模型的性能和调整超参数。它是从与训练集不同的图像中随机选择的一部分数据。通过在验证集上进行评估，可以监控模型的训练过程并调整模型的超参数，<br> 例如学习率、正则化参数等。验证集上的性能指标可以帮助选择最佳的模型，并防止过拟合。验证集的数据标注也需要包含目标物体的位置和类别信息。</p></li><li><p>测试集（Test Set）<br> 测试集是用于最终评估训练好的目标检测模型性能的数据集。它是与训练集和验证集完全独立的数据集。测试集中的图像对于模型来说是全新的，模型在这些图像上进行预测并生成目标检测结果。<br> 测试集的数据标注同样包含目标物体的位置和类别信息。通过与测试集的性能比较，可以得出模型在真实场景中的准确率、召回率、精确率等性能指标，评估模型的泛化能力和实际应用效果。</p></li></ul><p>这三个数据集在目标检测的训练过程中扮演着重要的角色，训练集用于模型的学习和参数优化，验证集用于超参数调优和模型选择，而测试集用于最终评估模型的性能和泛化能力。<br> 它们的目的是确保训练出的模型能够准确地检测出新的图像中的目标物体。</p><p><a href="https://github.com/kuisec/division-of-data/blob/main/DivisionOfData.py" target="_blank" rel="noopener noreferrer">数据集划分脚本</a></p><h3 id="数据集格式转换" tabindex="-1"><a class="header-anchor" href="#数据集格式转换"><span>数据集格式转换</span></a></h3><p>在目标检测任务中，常见的数据集格式有三种：<strong>VOC (xml)</strong>、<strong>COCO (json)</strong> 和 <strong>YOLO (txt)</strong> ：</p><ol><li><p><strong>VOC (Visual Object Classes) 数据集</strong>:</p><ul><li>VOC 数据集最初由英国牛津大学的计算机视觉小组创建，用于目标检测和图像分割任务。</li><li>包含20种常见的物体类别，例如人、车、狗、猫等。</li><li>VOC 数据集由以下五个部分构成： <ul><li><strong>JPEGImages</strong>：存放训练与测试的所有图片。</li><li><strong>Annotations</strong>：存放每张图片打完标签所对应的 XML 文件。</li><li><strong>ImageSets</strong>：存放训练集、验证集、测试集等图片的文件名。</li><li><strong>SegmentationClass</strong> 与 <strong>SegmentationObject</strong>：存放图像分割结果图，对目标检测任务无用。</li></ul></li><li>VOC 数据集的标签以 XML 文件形式存放，包含物体类别、位置信息等。</li></ul></li><li><p><strong>COCO (Common Objects in Context) 数据集</strong>:</p><ul><li>由微软研究院创建，旨在提供更广泛的物体类别和更丰富的场景上下文，促进计算机视觉研究。</li><li>COCO 数据集包含三种标注类型： <ul><li><strong>Object Instances</strong>：目标实例。</li><li><strong>Object Keypoints</strong>：目标上的关键点。</li><li><strong>Image Captions</strong>：看图说话。</li></ul></li><li>使用 JSON 文件存储，包含基本类型：info、image、license。</li></ul></li><li><p><strong>YOLO (You Only Look Once) 数据集</strong>:</p><ul><li>YOLO 数据集标注格式主要用于 YOLO 项目, 标签使用 TXT 文本进行保存，每行表示一个目标。</li><li>YOLO 标注格式示例：<div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>&lt;object-class&gt; &lt;x&gt; &lt;y&gt; &lt;width&gt; &lt;height&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div>其中： <ul><li><code>&lt;object-class&gt;</code>：物体类别。</li><li><code>&lt;x&gt;</code>、<code>&lt;y&gt;</code>：目标在图像中的中心坐标（相对于图像宽度和高度的比例）。</li><li><code>&lt;width&gt;</code>、<code>&lt;height&gt;</code>：目标的宽度和高度（相对于图像宽度和高度的比例）。</li></ul></li></ul></li></ol><p>(1) 目标检测中数据集格式之间的相互转换--coco、voc、yolo - <a href="https://zhuanlan.zhihu.com/p/461488682" target="_blank" rel="noopener noreferrer">知乎</a>.</p><p>(2) 目标检测两种常用的数据集COCO和VOC - Tutu007 - <a href="https://www.cnblogs.com/tully/p/18057834" target="_blank" rel="noopener noreferrer">博客园</a>.</p><p>(3) 目标检测数据集大全「包含VOC+COCO+YOLO三种格式+划分脚本+训练脚本」- <a href="https://zhuanlan.zhihu.com/p/679598127" target="_blank" rel="noopener noreferrer">知乎</a>.</p><p>(4) 目标检测任务中常用的数据集格式(voc、coco、yolo)_voc数据集格式-<a href="https://blog.csdn.net/weixin_45277161/article/details/130331788" target="_blank" rel="noopener noreferrer">CSDN博客</a>.</p><p>(5) VOC/COCO/YOLO数据总结及转换 - <a href="https://zhuanlan.zhihu.com/p/160103709" target="_blank" rel="noopener noreferrer">知乎专栏</a>.</p><p><a href="https://github.com/KKKSQJ/DeepLearning/tree/master/others/label_convert" target="_blank" rel="noopener noreferrer">数据集标注文件格式转换脚本</a></p><p>roboflow</p><h3 id="数据集配置" tabindex="-1"><a class="header-anchor" href="#数据集配置"><span>数据集配置</span></a></h3><p><strong>YOLOv8</strong> 的 <strong>yaml</strong> 配置文件用于定义模型的结构和训练参数，下面是常用参数的解释：</p><ol><li><p><strong><code>path</code></strong>：指定数据集的路径</p></li><li><p><strong><code>train</code></strong>：训练集的图像路径</p></li><li><p><strong><code>val</code></strong>：验证集的图像路径</p></li><li><p><strong><code>test</code></strong>：测试集的图像路径（这部分是可选的）</p></li><li><p><strong><code>names</code></strong>：定义目标类别的名称和对应的索引</p></li><li><p><strong><code>download</code></strong>：用于下载数据集（这部分是可选的）</p></li></ol><div class="language-yaml line-numbers-mode" data-highlighter="shiki" data-ext="yaml" data-title="yaml" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">path</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">../datasets/coco8</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # dataset root dir</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">train</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">images/train</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # train images (relative to &#39;path&#39;) </span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">val</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">images/val</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # val images (relative to &#39;path&#39;) </span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">test</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># test images (optional)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Classes (80 COCO classes)</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">names</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">  0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">person</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">  1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">bicycle</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">  2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">car</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # ...</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">  77</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">teddy bear</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">  78</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">hair drier</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">  79</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">toothbrush</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="yolov8目标检测" tabindex="-1"><a class="header-anchor" href="#yolov8目标检测"><span>yoloV8目标检测</span></a></h2><h3 id="开始训练" tabindex="-1"><a class="header-anchor" href="#开始训练"><span>开始训练</span></a></h3><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ultralytics </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;"> YOLO</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> __name__</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> ==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;__main__&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    model </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> YOLO</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;./models/yolov8n.pt&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    result_path </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;./result/detect&#39;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    result_name </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;train1&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    model.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">train</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">data</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;datasets/DambV0/DambV0.yaml&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">epochs</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">500</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">batch</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">64</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">project</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">result_path, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">name</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">result_name, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">workers</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    model.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">val</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="train方法参数" tabindex="-1"><a class="header-anchor" href="#train方法参数"><span>train方法参数</span></a></h3><p>YOLOv8的<code>train</code>方法可以接受多个参数，用于配置训练过程。以下是这些参数的详细说明：</p><ol><li><p><strong><code>data</code></strong>：指定数据集的配置文件路径。这个配置文件描述了数据集的类别、图像路径、标签等信息</p></li><li><p><strong><code>epochs</code></strong>：训练的轮数。这是指模型将遍历整个训练数据集的次数。通常，较大的<code>epochs</code>值可以提高模型的性能，但也可能导致过拟合。推荐的常用值为300到1200</p></li><li><p><strong><code>batch</code></strong>：每个批次中的图像数量。批量大小影响训练速度和内存需求。较大的批量大小可以加快训练速度，但可能需要更多的内存。推荐的常用值因任务而异，一般在16到64之间</p></li><li><p><strong><code>imgsz</code></strong>：训练图像的尺寸。通常，较大的图像尺寸可以提高模型的性能，但也会增加计算成本。推荐的常用值为416、512或640</p></li><li><p><strong><code>device</code></strong>：指定训练使用的设备，如GPU或CPU。如果不指定，将自动选择可用的GPU（如果有）；否则将使用CPU</p></li><li><p><strong><code>weights</code></strong>：预训练模型的权重文件路径。如果指定了预训练权重，模型将从这些权重开始训练</p></li><li><p><strong><code>multi_scale</code></strong>：是否使用多尺度训练。如果设置为True，模型将在不同尺度的图像上进行训练，有助于提高模型的鲁棒性</p></li><li><p><strong><code>augment</code></strong>：是否使用数据增强。数据增强可以帮助模型更好地泛化</p></li><li><p><strong><code>cache_images</code></strong>：是否缓存图像。如果设置为True，模型将在内存中缓存图像以加快训练速度</p></li><li><p><strong><code>project</code></strong> 和 <strong><code>name</code></strong>：用于指定训练结果的保存路径。<code>project</code>表示文件夹名称，<code>name</code>表示结果的名称</p></li></ol><h3 id="图像检测" tabindex="-1"><a class="header-anchor" href="#图像检测"><span>图像检测</span></a></h3>`,50)]))}const o=s(e,[["render",n],["__file","yolo.html.vue"]]),k=JSON.parse('{"path":"/python/Project/yolo.html","title":"YOLOv8","lang":"en-US","frontmatter":{"order":-15,"title":"YOLOv8","shortTitle":"yolov8","description":"yolo快速入门 yolov8仓库地址：https://github.com/ultralytics/ultralytics yolov8官方文档：https://docs.ultralytics.com yolov8的安装 使用yolov8需要 python>=3.8 和 PyTorch>=1.8 的环境，参照：Python常用环境的安装 Pip i...","head":[["meta",{"property":"og:url","content":"https://x.app/python/Project/yolo.html"}],["meta",{"property":"og:site_name","content":"doc"}],["meta",{"property":"og:title","content":"YOLOv8"}],["meta",{"property":"og:description","content":"yolo快速入门 yolov8仓库地址：https://github.com/ultralytics/ultralytics yolov8官方文档：https://docs.ultralytics.com yolov8的安装 使用yolov8需要 python>=3.8 和 PyTorch>=1.8 的环境，参照：Python常用环境的安装 Pip i..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-01-10T15:19:41.000Z"}],["meta",{"property":"article:author","content":"ventixy"}],["meta",{"property":"article:modified_time","content":"2025-01-10T15:19:41.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"YOLOv8\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-01-10T15:19:41.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"ventixy\\",\\"url\\":\\"https://www.ventix.top\\"}]}"]]},"headers":[{"level":2,"title":"yolo快速入门","slug":"yolo快速入门","link":"#yolo快速入门","children":[{"level":3,"title":"yolov8的安装","slug":"yolov8的安装","link":"#yolov8的安装","children":[]},{"level":3,"title":"预训练权重","slug":"预训练权重","link":"#预训练权重","children":[]},{"level":3,"title":"python代码示例","slug":"python代码示例","link":"#python代码示例","children":[]}]},{"level":2,"title":"数据集准备","slug":"数据集准备","link":"#数据集准备","children":[{"level":3,"title":"标注数据集","slug":"标注数据集","link":"#标注数据集","children":[]},{"level":3,"title":"划分数据集","slug":"划分数据集","link":"#划分数据集","children":[]},{"level":3,"title":"数据集格式转换","slug":"数据集格式转换","link":"#数据集格式转换","children":[]},{"level":3,"title":"数据集配置","slug":"数据集配置","link":"#数据集配置","children":[]}]},{"level":2,"title":"yoloV8目标检测","slug":"yolov8目标检测","link":"#yolov8目标检测","children":[{"level":3,"title":"开始训练","slug":"开始训练","link":"#开始训练","children":[]},{"level":3,"title":"train方法参数","slug":"train方法参数","link":"#train方法参数","children":[]},{"level":3,"title":"图像检测","slug":"图像检测","link":"#图像检测","children":[]}]}],"git":{"createdTime":1736522381000,"updatedTime":1736522381000,"contributors":[{"name":"drizzle","email":"msdrizzle@outlook.com","commits":1}]},"readingTime":{"minutes":7.86,"words":2359},"filePathRelative":"python/Project/yolo.md","localizedDate":"January 10, 2025","excerpt":"<h2>yolo快速入门</h2>\\n<p>yolov8仓库地址：<a href=\\"https://github.com/ultralytics/ultralytics\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://github.com/ultralytics/ultralytics</a></p>\\n<p>yolov8官方文档：<a href=\\"https://docs.ultralytics.com\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://docs.ultralytics.com</a></p>","autoDesc":true}');export{o as comp,k as data};
